{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Instalar dependências"
      ],
      "metadata": {
        "id": "sWttGOzl15xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: instalar pacotes\n",
        "!pip install --upgrade pip\n",
        "!pip install openai soundfile pydub gtts\n"
      ],
      "metadata": {
        "id": "xtSrOl3P167f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Configurar chave da OpenAI"
      ],
      "metadata": {
        "id": "xTaZM5pY19fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: definir chave (execute e cole sua chave quando solicitado)\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = input(\"Cole sua OPENAI_API_KEY aqui e pressione Enter: \").strip()\n",
        "print(\"Chave definida\")\n",
        "\n",
        "#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\n"
      ],
      "metadata": {
        "id": "OvznZ4o81-y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Gravar áudio no navegador e enviar para o Colab"
      ],
      "metadata": {
        "id": "akrjemn62qaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: widget para gravar áudio no navegador e salvar como input.wav\n",
        "from IPython.display import HTML, display, Javascript\n",
        "from google.colab import files\n",
        "\n",
        "record_js = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
        "const b2text = async (blob) => {\n",
        "  const data = await blob.arrayBuffer();\n",
        "  const base64 = btoa(String.fromCharCode(...new Uint8Array(data)));\n",
        "  return base64;\n",
        "}\n",
        "async function record() {\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({audio:true});\n",
        "  const mediaRecorder = new MediaRecorder(stream);\n",
        "  let chunks = [];\n",
        "  mediaRecorder.ondataavailable = e => chunks.push(e.data);\n",
        "  mediaRecorder.start();\n",
        "  const stopButton = document.createElement('button');\n",
        "  stopButton.textContent = 'Parar gravação';\n",
        "  document.body.appendChild(stopButton);\n",
        "  await new Promise(resolve => stopButton.onclick = resolve);\n",
        "  mediaRecorder.stop();\n",
        "  await new Promise(resolve => mediaRecorder.onstop = resolve);\n",
        "  const blob = new Blob(chunks, {type:'audio/webm'});\n",
        "  const base64 = await b2text(blob);\n",
        "  const filename = 'input.webm';\n",
        "  const link = document.createElement('a');\n",
        "  link.href = 'data:audio/webm;base64,' + base64;\n",
        "  link.download = filename;\n",
        "  document.body.appendChild(link);\n",
        "  link.click();\n",
        "  document.body.removeChild(link);\n",
        "  stopButton.remove();\n",
        "}\n",
        "record();\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(\"<b>Pressione o botão 'Parar gravação' que aparecerá na página quando estiver pronto.</b>\"))\n",
        "display(Javascript(record_js))\n"
      ],
      "metadata": {
        "id": "ajGqK3LA2ru_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: fazer upload do arquivo gravado para o Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # selecione o input.webm baixado\n",
        "print(list(uploaded.keys()))\n"
      ],
      "metadata": {
        "id": "CKIEVJlz26Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Converter WebM para WAV"
      ],
      "metadata": {
        "id": "xO_mUbNz3VHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: converter input.webm para input.wav\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "in_filename = next(iter(uploaded.keys()))\n",
        "out_filename = \"input.wav\"\n",
        "\n",
        "audio = AudioSegment.from_file(in_filename)\n",
        "audio = audio.set_frame_rate(16000).set_channels(1)\n",
        "audio.export(out_filename, format=\"wav\")\n",
        "print(\"Exportado para\", out_filename)\n"
      ],
      "metadata": {
        "id": "Qp_MHd6f3YH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Transcrever com Whisper via API OpenAI"
      ],
      "metadata": {
        "id": "KuJhUBeZ3Zye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: transcrever usando Whisper via API OpenAI\n",
        "import openai, os, json\n",
        "from openai import OpenAI # Import the OpenAI client\n",
        "\n",
        "# Initialize the client outside the function if it's used globally, or here if scoped to this cell\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "audio_file_path = \"input.wav\"\n",
        "with open(audio_file_path, \"rb\") as f:\n",
        "    # Use the new client interface for audio transcriptions\n",
        "    try:\n",
        "        # The correct call in openai>=1.0.0 is client.audio.transcriptions.create\n",
        "        resp = client.audio.transcriptions.create(file=f, model=\"whisper-1\")\n",
        "        text = resp.text # Access text attribute from the response object\n",
        "    except Exception as e:\n",
        "        # If the above fails (e.g., due to a very old client or an unexpected error),\n",
        "        # this fallback might not be necessary or might need re-evaluation.\n",
        "        # The old openai.Audio.transcribe is also deprecated.\n",
        "        # For consistency, it's better to stick to the new client interface.\n",
        "        print(f\"An error occurred: {e}. Trying the old interface if it were available...\")\n",
        "        raise # Re-raise the exception as the old interface is likely not available either.\n",
        "\n",
        "print(\"Transcrição detectada:\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "N9Zc-2vx3agm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Enviar a transcrição ao ChatGPT e obter resposta"
      ],
      "metadata": {
        "id": "aQWV9GXk3c4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: enviar para ChatGPT (gpt-3.5-turbo)\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Você é um assistente útil que responde em português.\"},\n",
        "    {\"role\": \"user\", \"content\": text}\n",
        "]\n",
        "\n",
        "resp = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, max_tokens=300)\n",
        "reply = resp.choices[0].message.content.strip()\n",
        "print(\"Resposta do ChatGPT:\")\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "MlkPTCCa3eL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 Converter resposta em áudio com gTTS e reproduzir no Colab"
      ],
      "metadata": {
        "id": "iHJCdvG93ft-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: gerar áudio com gTTS e tocar no notebook\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "tts = gTTS(reply, lang=\"pt\")\n",
        "tts.save(\"reply.mp3\")\n",
        "display(Audio(\"reply.mp3\", autoplay=True))\n",
        "print(\"Áudio gerado e reproduzido\")\n"
      ],
      "metadata": {
        "id": "fXC6ac1d3g12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8 Fluxo completo em uma função"
      ],
      "metadata": {
        "id": "XBJq9x2H3iF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: função que integra tudo (assumindo input.wav já presente)\n",
        "def run_pipeline(audio_path=\"input.wav\"):\n",
        "    # 1 Transcrever\n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        try:\n",
        "            resp = openai.Audio.transcriptions.create(file=f, model=\"whisper-1\")\n",
        "            text = resp[\"text\"]\n",
        "        except:\n",
        "            resp = openai.Audio.transcribe(model=\"whisper-1\", file=f)\n",
        "            text = resp[\"text\"]\n",
        "    print(\"Transcrição:\", text)\n",
        "\n",
        "    # 2 ChatGPT\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente útil que responde em português.\"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    resp = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, max_tokens=300)\n",
        "    reply = resp.choices[0].message.content.strip()\n",
        "    print(\"Resposta:\", reply)\n",
        "\n",
        "    # 3 TTS\n",
        "    tts = gTTS(reply, lang=\"pt\")\n",
        "    tts.save(\"reply.mp3\")\n",
        "    display(Audio(\"reply.mp3\", autoplay=True))\n",
        "\n",
        "# executar pipeline\n",
        "run_pipeline(\"input.wav\")\n"
      ],
      "metadata": {
        "id": "hKoWuUNE3j3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}